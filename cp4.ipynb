{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b0ee77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Célula 0 — Instalar/atualizar bibliotecas necessárias\n",
    "# ============================================================\n",
    "import sys, subprocess\n",
    "\n",
    "def pip_install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
    "\n",
    "for pkg in [\"pandas\",\"numpy\",\"matplotlib\",\"scikit-learn\",\"statsmodels\"]:\n",
    "    try:\n",
    "        __import__(pkg.split(\"==\")[0].split(\">=\")[0])\n",
    "    except Exception:\n",
    "        pip_install(pkg)\n",
    "\n",
    "import pandas as pd, numpy as np, matplotlib, sklearn, statsmodels\n",
    "print(\"Bibliotecas carregadas com sucesso!\")\n",
    "\n",
    "# ============================================================\n",
    "# Imports principais\n",
    "# ============================================================\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "plt.rcParams.update({\"figure.figsize\": (9, 4)})\n",
    "\n",
    "# ============================================================\n",
    "# Função auxiliar para upload no Colab\n",
    "# ============================================================\n",
    "def colab_upload(expected_ext=None):\n",
    "    \"\"\"Faz upload no Colab e retorna Path do arquivo válido\"\"\"\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        fname = list(uploaded.keys())[0]\n",
    "        if expected_ext and not fname.endswith(expected_ext):\n",
    "            raise ValueError(f\"Arquivo enviado não é {expected_ext}. Você enviou: {fname}\")\n",
    "        return Path(fname)\n",
    "    except Exception as e:\n",
    "        print(\"Upload falhou ou não está no Colab:\", e)\n",
    "        return None\n",
    "\n",
    "# ============================================================\n",
    "# Parte 1 + 2 — Dataset IHEPC\n",
    "# ============================================================\n",
    "print(\"\\n=== Upload do dataset household_power_consumption.txt ===\")\n",
    "IHEPC_TXT = colab_upload(expected_ext=\".txt\")\n",
    "if IHEPC_TXT is None:\n",
    "    IHEPC_TXT = Path(\"household_power_consumption.txt\")  # caminho manual se não for Colab\n",
    "print(\"Arquivo TXT:\", IHEPC_TXT)\n",
    "\n",
    "def load_ihepc(parse_datetime=True):\n",
    "    df = pd.read_csv(\n",
    "        IHEPC_TXT,\n",
    "        sep=';',\n",
    "        na_values=['?'],\n",
    "        dtype={\n",
    "            'Global_active_power':'float64',\n",
    "            'Global_reactive_power':'float64',\n",
    "            'Voltage':'float64',\n",
    "            'Global_intensity':'float64',\n",
    "            'Sub_metering_1':'float64',\n",
    "            'Sub_metering_2':'float64',\n",
    "            'Sub_metering_3':'float64'\n",
    "        },\n",
    "        low_memory=False\n",
    "    )\n",
    "    if parse_datetime:\n",
    "        df['Datetime'] = pd.to_datetime(\n",
    "            df['Date'] + ' ' + df['Time'],\n",
    "            format='%d/%m/%Y %H:%M:%S',\n",
    "            errors='coerce'\n",
    "        )\n",
    "        df['Date_dt'] = pd.to_datetime(\n",
    "            df['Date'],\n",
    "            format='%d/%m/%Y',\n",
    "            errors='coerce'\n",
    "        )\n",
    "    return df\n",
    "\n",
    "# Carregar\n",
    "df = load_ihepc()\n",
    "print(\"\\nPrimeiras 10 linhas:\")\n",
    "display(df.head(10))\n",
    "\n",
    "# Exercícios 3–25 (resumidos aqui para caber)\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isna().sum())\n",
    "\n",
    "df['DayOfWeek'] = df['Date_dt'].dt.day_name()\n",
    "df_2007 = df[df['Date_dt'].dt.year == 2007]\n",
    "daily_mean_all = df.groupby('Date_dt')['Global_active_power'].mean()\n",
    "print(\"Dia com maior GAP médio:\", daily_mean_all.idxmax(), daily_mean_all.max())\n",
    "\n",
    "# Histograma de Voltage\n",
    "df['Voltage'].dropna().plot(kind='hist', bins=50)\n",
    "plt.title(\"Distribuição de Voltage\"); plt.show()\n",
    "\n",
    "# Regressão GAP ~ GI\n",
    "valid = df[['Global_active_power','Global_intensity']].dropna()\n",
    "X = valid[['Global_intensity']]\n",
    "y = valid['Global_active_power']\n",
    "lr = LinearRegression().fit(X,y)\n",
    "rmse = mean_squared_error(y, lr.predict(X), squared=False)\n",
    "print(\"Regressão Linear GAP~GI -> Coef:\", lr.coef_[0], \"RMSE:\", rmse)\n",
    "\n",
    "# ============================================================\n",
    "# Parte 3 — Dataset Appliances\n",
    "# ============================================================\n",
    "print(\"\\n=== Upload do dataset appliances_energy_prediction.csv ===\")\n",
    "APPLIANCES_CSV = colab_upload(expected_ext=\".csv\")\n",
    "if APPLIANCES_CSV is None:\n",
    "    APPLIANCES_CSV = Path(\"appliances_energy_prediction.csv\")\n",
    "print(\"Arquivo CSV:\", APPLIANCES_CSV)\n",
    "\n",
    "ap = pd.read_csv(APPLIANCES_CSV)\n",
    "ap['date'] = pd.to_datetime(ap['date'])\n",
    "print(\"\\n.head() do Appliances:\")\n",
    "display(ap.head())\n",
    "\n",
    "# Exercícios 26–35\n",
    "ap['Appliances'].plot(kind='hist', bins=50)\n",
    "plt.title(\"Distribuição de Appliances\"); plt.show()\n",
    "\n",
    "print(\"\\nCorrelação com Appliances (top 10):\")\n",
    "print(ap.corr(numeric_only=True)['Appliances'].sort_values(ascending=False).head(10))\n",
    "\n",
    "# PCA\n",
    "num_cols_ap = ap.select_dtypes(include=[np.number]).columns\n",
    "ap_scaled = ap.copy()\n",
    "ap_scaled[num_cols_ap] = MinMaxScaler().fit_transform(ap[num_cols_ap])\n",
    "X_ap = ap_scaled[num_cols_ap].dropna()\n",
    "pca_ap = PCA(n_components=2).fit(X_ap)\n",
    "print(\"\\nVariância explicada PCA (Appliances):\", pca_ap.explained_variance_ratio_)\n",
    "\n",
    "# Regressão múltipla\n",
    "X = ap[num_cols_ap].drop(columns=['Appliances']).fillna(0)\n",
    "y = ap['Appliances']\n",
    "lin = LinearRegression().fit(X,y)\n",
    "print(\"\\nRegressão Linear Múltipla — R²:\", lin.score(X,y))\n",
    "\n",
    "# Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state=42).fit(X,y)\n",
    "print(\"Random Forest RMSE:\", mean_squared_error(y, rf.predict(X), squared=False))\n",
    "\n",
    "# Classificação binária\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "ap['HighUse'] = (ap['Appliances'] > ap['Appliances'].median()).astype(int)\n",
    "X_cls = X.fillna(X.median())\n",
    "y_cls = ap['HighUse']\n",
    "Xtr,Xte,ytr,yte = train_test_split(X_cls,y_cls,test_size=0.3,random_state=42,stratify=y_cls)\n",
    "\n",
    "rf_cls = RandomForestClassifier(random_state=42).fit(Xtr,ytr)\n",
    "y_pred = rf_cls.predict(Xte)\n",
    "\n",
    "print(\"\\nMatriz de confusão:\")\n",
    "print(confusion_matrix(yte, y_pred))\n",
    "print(\"\\nMétricas de avaliação:\")\n",
    "print(\"Accuracy :\", accuracy_score(yte, y_pred))\n",
    "print(\"Precision:\", precision_score(yte, y_pred))\n",
    "print(\"Recall   :\", recall_score(yte, y_pred))\n",
    "print(\"F1-Score :\", f1_score(yte, y_pred))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
